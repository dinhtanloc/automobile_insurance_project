{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd8c11c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler,OneHotEncoder,StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "622aee0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d162d6",
   "metadata": {},
   "source": [
    "* kiểm tra và tạo các thư mục (nếu chưa có)\n",
    "* tập test 33%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84bdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import clone\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from kerastuner.tuners import RandomSearch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e81211d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "y_train=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "x_test=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "y_test=pd.read_excel(f'{save_dir}/y_test.xlsx')\n",
    "class_weights_dict=dict(np.load(f'{exps_dir}/feature1/class_weights_dict.npz',allow_pickle=True))['class_weights_dict']\n",
    "class_weights_dict = {key: value for key, value in class_weights_dict.item().items()}\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f87f80",
   "metadata": {},
   "source": [
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số mô hình SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bccdfc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Hyperparameters:\n",
      "{'C': 4.586999987157974, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Định nghĩa không gian siêu tham số\n",
    "param_dist = {'C': uniform(0.1, 10),\n",
    "              'kernel': ['linear', 'rbf', 'poly'],\n",
    "              'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7))}\n",
    "\n",
    "# Khởi tạo mô hình SVM\n",
    "svm_model = SVC()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search = RandomizedSearchCV(svm_model, param_distributions=param_dist, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình SVM tốt nhất\n",
    "print(\"Best SVM Hyperparameters:\")\n",
    "print(random_search.best_params_)\n",
    "C=random_search.best_params_['C']\n",
    "gamma=random_search.best_params_['gamma']\n",
    "kernel=random_search.best_params_['kernel']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6844fde",
   "metadata": {},
   "source": [
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số mô hình GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f28144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Gradient Boosting Hyperparameters:\n",
      "{'learning_rate': 0.10788102240182319, 'max_depth': 7, 'n_estimators': 161, 'subsample': 0.9783219012544492}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Gradient Boosting\n",
    "param_dist_gb = {'n_estimators': randint(50, 200),\n",
    "                 'learning_rate': uniform(0.01, 0.1),\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'subsample': uniform(0.6, 0.4)}\n",
    "\n",
    "# Khởi tạo mô hình Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_gb = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_gb.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Gradient Boosting tốt nhất\n",
    "print(\"Best Gradient Boosting Hyperparameters:\")\n",
    "print(random_search_gb.best_params_)\n",
    "best_gb_model = random_search_gb.best_estimator_\n",
    "max_depthgb=random_search_gb.best_params_['max_depth']\n",
    "learning_rate=random_search_gb.best_params_['learning_rate']\n",
    "n_estimatorsgb=random_search_gb.best_params_['n_estimators']\n",
    "subsample=random_search_gb.best_params_['subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb1d4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Hyperparameters:\n",
      "{'n_estimators': 300, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Định nghĩa không gian siêu tham số\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20],\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_rf = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_rf.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Random Forest tốt nhất\n",
    "print(\"Best Random Forest Hyperparameters:\")\n",
    "print(random_search_rf.best_params_)\n",
    "n_estimators=random_search_rf.best_params_['n_estimators']\n",
    "max_depth=random_search_rf.best_params_['max_depth']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2703b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Gradient Boosting\n",
    "param_dist_gb = {'n_estimators': randint(50, 200),\n",
    "                 'learning_rate': uniform(0.01, 0.1),\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'subsample': uniform(0.6, 0.4)}\n",
    "\n",
    "# Khởi tạo mô hình Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_gb = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_gb.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Gradient Boosting tốt nhất\n",
    "print(\"Best Gradient Boosting Hyperparameters:\")\n",
    "print(random_search_gb.best_params_)\n",
    "best_gb_model = random_search_gb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Gradient Boosting\n",
    "param_dist_gb = {'n_estimators': randint(50, 200),\n",
    "                 'learning_rate': uniform(0.01, 0.1),\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'subsample': uniform(0.6, 0.4)}\n",
    "\n",
    "# Khởi tạo mô hình Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_gb = RandomizedSearchCV(gb_model, param_distributions=param_dist_gb, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_gb.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Gradient Boosting tốt nhất\n",
    "print(\"Best Gradient Boosting Hyperparameters:\")\n",
    "print(random_search_gb.best_params_)\n",
    "best_gb_model = random_search_gb.best_estimator_\n",
    "max_depthgb=random_search_gb.best_params_['max_depth']\n",
    "learning_rate=random_search_gb.best_params_['learning_rate']\n",
    "n_estimatorsgb=random_search_gb.best_params_['n_estimators']\n",
    "subsample=random_search_gb.best_params_['subsample']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55430981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Định nghĩa không gian siêu tham số cho Decision Tree\n",
    "param_dist_dt = {'criterion': ['gini', 'entropy'],\n",
    "                 'splitter': ['best', 'random'],\n",
    "                 'max_depth': randint(3, 10),\n",
    "                 'min_samples_split': randint(2, 20),\n",
    "                 'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "# Khởi tạo mô hình Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số\n",
    "random_search_dt = RandomizedSearchCV(dt_model, param_distributions=param_dist_dt, n_iter=5, scoring='accuracy', cv=5)\n",
    "random_search_dt.fit(x_train, y_train)\n",
    "\n",
    "# In ra thông tin của mô hình Decision Tree tốt nhất\n",
    "print(\"Best Decision Tree Hyperparameters:\")\n",
    "print(random_search_dt.best_params_)\n",
    "best_dt_model = random_search_dt.best_estimator_\n",
    "criterion=random_search_dt.best_params_['criterion']\n",
    "max_depthdt=random_search_dt.best_params_['max_depth']\n",
    "min_samples_leaf=random_search_dt.best_params_['min_samples_leaf']\n",
    "splitter=random_search_dt.best_params_['splitter']\n",
    "min_samples_split=random_search_dt.best_params_['min_samples_split']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu', input_dim=x_train.shape[1]))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('units_2', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('units_3', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('units_4', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(units=hp.Int('units_5', min_value=32, max_value=512, step=32),\n",
    "                           activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "# Tạo đối tượng RandomSearch tuner\n",
    "tuner = RandomSearch(build_model, objective='val_accuracy', max_trials=5)\n",
    "\n",
    "# Tìm kiếm tham số tốt nhất\n",
    "tuner.search(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "\n",
    "# Lấy mô hình tốt nhất\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8917077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = tuner.oracle.get_best_trials(1)[0].hyperparameters.values\n",
    "best_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1854cb",
   "metadata": {},
   "source": [
    "# Sử dụng RandomizedSearchCV để tinh chỉnh siêu tham số mô hình RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Hàm để xây dựng mô hình đầu ra\n",
    "def model_output(unit1, unit2, unit3, unit4, unit5):\n",
    "    stacked_model = Sequential()\n",
    "    stacked_model.add(Dense(unit1, activation='relu'))\n",
    "    stacked_model.add(BatchNormalization())\n",
    "    stacked_model.add(Dropout(0.5))\n",
    "\n",
    "    # Thêm các lớp ẩn\n",
    "    stacked_model.add(Dense(unit2, activation='relu'))\n",
    "    stacked_model.add(BatchNormalization())\n",
    "    stacked_model.add(Dropout(0.5))\n",
    "\n",
    "    stacked_model.add(Dense(unit3, activation='relu'))\n",
    "    stacked_model.add(BatchNormalization())\n",
    "    stacked_model.add(Dropout(0.5))\n",
    "\n",
    "    stacked_model.add(Dense(unit4, activation='relu'))\n",
    "    stacked_model.add(BatchNormalization())\n",
    "    stacked_model.add(Dropout(0.5))\n",
    "\n",
    "    stacked_model.add(Dense(unit5, activation='relu'))\n",
    "    stacked_model.add(BatchNormalization())\n",
    "    stacked_model.add(Dropout(0.5))\n",
    "\n",
    "    # Lớp đầu ra với activation function 'sigmoid' cho bài toán phân lớp nhị phân\n",
    "    stacked_model.add(Dense(1, activation='sigmoid'))\n",
    "    stacked_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return stacked_model\n",
    "\n",
    "# # Lấy các tham số tối ưu từ tuner\n",
    "# best_trials = tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values\n",
    "\n",
    "# # Xây dựng mô hình stacked với các tham số tối ưu\n",
    "# stacked_model = model_output(best_trials['units_1'], best_trials['units_2'], best_trials['units_3'],\n",
    "#                               best_trials['units_4'], best_trials['units_5'])\n",
    "# stacked_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Huấn luyện mô hình stacked trên dữ liệu đầu ra của các mô hình cơ sở\n",
    "# stacked_model.fit(stacked_input, y_test, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Dự đoán và đánh giá mô hình stacked\n",
    "# binary_stacked_pred = stacked_model.predict(stacked_input)\n",
    "# binary_stacked_pred = (binary_stacked_pred > 0.5).astype(int)\n",
    "\n",
    "# # Sử dụng cú pháp trích xuất trên NumPy array\n",
    "# accuracy_stacked = accuracy_score(y_test_array, binary_stacked_pred)\n",
    "# print(f'Accuracy of Stacked Model: {accuracy_stacked}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef43bed6",
   "metadata": {},
   "source": [
    "# Sử dụng Ensemble Learning, cụ thể là Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c4c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import numpy as np\n",
    "def create_keras_model():\n",
    "    # Thêm các lớp khác vào đây\n",
    "    best_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return best_model\n",
    "\n",
    "# keras_clf = KerasClassifier(build_fn=create_keras_model, epochs=10)\n",
    "rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "gb_model = SVC(C=C,kernel=kernel,gamma=gamma,probability=True)\n",
    "dtc_model=DecisionTreeClassifier(criterion=criterion,max_depth=max_depthdt,min_samples_leaf=min_samples_leaf,min_samples_split=min_samples_split,splitter=splitter)\n",
    "bg_model=GradientBoostingClassifier(n_estimators=n_estimatorsgb, learning_rate=learning_rate, max_depth=max_depthgb, subsample=subsample)\n",
    "# Huấn luyện các mô hình cơ sở\n",
    "rf_model.fit(x_train, y_train)\n",
    "gb_model.fit(x_train, y_train)\n",
    "dtc_model.fit(x_train, y_train)\n",
    "bg_model.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# Dự đoán đầu ra của các mô hình cơ sở\n",
    "rf_pred = rf_model.predict(x_test)\n",
    "gb_pred = gb_model.predict(x_test)\n",
    "dtc_pred = dtc_model.predict(x_test)\n",
    "bg_pred = bg_model.predict(x_test)\n",
    "\n",
    "\n",
    "# keras_pred = keras_clf.predict(x_test)\n",
    "stacked_input = np.column_stack((rf_pred,dtc_pred,gb_pred, bg_pred))\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=model_output, unit1=best_trials['units_1'], unit2=best_trials['units_2'], unit3=best_trials['units_3'], unit4=best_trials['units_4'], unit5=best_trials['units_5'])\n",
    "\n",
    "# Clone lại để tránh thay đổi trực tiếp vào mô hình gốc\n",
    "keras_clf = clone(keras_clf)\n",
    "\n",
    "# Xây dựng mô hình stacking\n",
    "stacked_model = StackingClassifier(\n",
    "    classifiers=[rf_model, dtc_model,gb_model, bg_model,keras_clf],\n",
    "    meta_classifier=dtc_model\n",
    ")\n",
    "\n",
    "# Tiếp tục với việc huấn luyện và đánh giá mô hình stacking\n",
    "stacked_model.fit(stacked_input, y_test)\n",
    "stacked_pred = stacked_model.predict(stacked_input)\n",
    "stacked_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70c668",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff75e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_model.fit(stacked_input, y_test)\n",
    "# Dự đoán và đánh giá mô hình stacked\n",
    "stacked_pred = stacked_model.predict(stacked_input)\n",
    "stacked_pred_binary = (stacked_pred > 0.5).astype(int)\n",
    "accuracy_stacked = accuracy_score(y_test, stacked_pred_binary)\n",
    "print(f'Accuracy of Stacked Model: {accuracy_stacked}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173f8e2c",
   "metadata": {},
   "source": [
    "* Sử dụng thư viện **imbalanced-learn** để thực hiện Oversampling bằng phương pháp **SMOTE (Synthetic Minority Over-sampling Technique).** \n",
    "\n",
    "#### Giải thích:\n",
    "* Vì tập dữ liệu của nhóm là tập dữ liệu phân loại không cân bằng => **SMOTE** được sử dụng để tăng cường dữ liệu trong trường hợp mẫu của lớp thiểu số (minority class) quá ít so với lớp đa số (majority class), giúp cân bằng dữ liệu và cải thiện hiệu suất của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = accuracy_score(y_test, stacked_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Hiển thị báo cáo phân loại\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, stacked_pred,labels=[1,0]))\n",
    "\n",
    "# # Hiển thị ma trận nhầm lẫn\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(confusion_matrix(y_test, y_pred,labels=[1,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f218b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "\n",
    "\n",
    "# Tính ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_test, stacked_pred,labels=[1,0])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[1,0], yticklabels=[1,0])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a418ea",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Nhóm xây dựng một mạng Netual network ứng dụng kỹ thuật trong học sâu như callbacks, đánh trọng số,.... Nhưng không khắc phục được tình trạng (imbalanced variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    if isinstance(prediction, (np.ndarray, pd.Series)):\n",
    "        prediction = prediction.item()  # Hoặc sử dụng prediction[0] hoặc prediction.iloc[0]\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hopdonggianlan = 0\n",
    "\n",
    "def check_output(y_test,stacked_pred):\n",
    "    solandung = 0\n",
    "    hopdonggianlan=0\n",
    "    y_test=np.array(y_test)\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i]==stacked_pred[i]:\n",
    "            solandung+=1\n",
    "            if y_test[i]==1:\n",
    "                hopdonggianlan+=1\n",
    "                \n",
    "    return solandung,hopdonggianlan\n",
    "check_output(y_test,stacked_pred)            \n",
    "solandung=check_output(y_test,stacked_pred)[0]\n",
    "hopdonggianlan=check_output(y_test,stacked_pred)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a65590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n",
    "print(f\"Số hợp đồng gian lận trong lần kiểm tra: {hopdonggianlan} chiếm khoảng {(hopdonggianlan/len(y_test[y_test['fraud_reported']==1]))*100}% so với thực tế\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec44a6",
   "metadata": {},
   "source": [
    "* Ta có thể thấy trong tất cả các lần dự đoán, mô hình đều dự đoán 'N'(lớp 0). Đó là lí do tại sao chỉ số 'accuracy'lại cao như vậy ( vốn tập dữ liệu bị mất cân bằng lớp lớp 0 gấp 3 lần lớp 1)\n",
    "\n",
    "#### => Kết luận: Ta không dựa vào chỉ số 'accuracy' để đánh giá các mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d230486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fe14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169dd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aefbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
