{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35976737",
   "metadata": {},
   "source": [
    "# Data Automobie Insurance\n",
    "    - Tập dữ liệu Automobile Insurance là các thông tin về các đơn yêu cầu bồi thường do một công ty bảo hiểm cung cấp. Từ những thông tin của khách hàng và các số liệu thực tế do hãng bảo hiểm cung cấp, nhóm tiến hành thực hiện đề tài dự đoán xem hồ sơ đó có bị gian lận hay không\n",
    "    - Dữ liệu bao gồm 41 cột và 1000 dòng. Các thông tin của dataset bao gồm:\n",
    "    months_as_customer: Số tháng mà người gửi đơn đã làm khách hàng với công ty bảo hiểm.\n",
    "    age: Tuổi của người được bảo hiểm.\n",
    "    policy_number: Một số duy nhất xác định chính sách bảo hiểm.\n",
    "    policy_bind_date: Ngày bắt đầu hợp đồng bảo hiểm.\n",
    "    policy_state: Bang nơi chính sách bảo hiểm được phát hành.\n",
    "    policy_csl: Giới hạn Kết hợp Đơn (CSL) chỉ ra số tiền tối đa mà chính sách sẽ trả mỗi sự cố.\n",
    "    policy_deductible: Số tiền người giữ chính sách phải trả trước khi công ty bảo hiểm chi trả một đơn đăng ký.\n",
    "    policy_annual_premium: Số tiền phí hàng năm cho chính sách bảo hiểm.\n",
    "    umrrella_limit: Số tiền bảo hiểm trách nhiệm bổ sung ngoài giới hạn của các chính sách cá nhân.\n",
    "    insured_zip: Mã ZIP của người được bảo hiểm.\n",
    "    insured_sex: Giới tính của người được bảo hiểm.\n",
    "    insured_education_level: Trình độ giáo dục của người được bảo hiểm.\n",
    "    insured_occupation: Nghề nghiệp của người được bảo hiểm.\n",
    "    insured_hobbies: Sở thích của người được bảo hiểm.\n",
    "    insured_relationship: Mối quan hệ của người được bảo hiểm với người giữ chính sách.\n",
    "    capital-gains: Lợi nhuận vốn được báo cáo của người được bảo hiểm.\n",
    "    capital-loss: Thiệt hại vốn được báo cáo của người được bảo hiểm.\n",
    "    incident_date: Ngày của sự cố mà đơn được đề xuất.\n",
    "    incident_type: Loại sự cố (ví dụ: va chạm, trộm cắp).\n",
    "    collision_type: Loại va chạm nếu có.\n",
    "    incident_severity: Mức độ nghiêm trọng của sự cố.\n",
    "    authorities_contacted: Cơ quan nào đã liên hệ về sự cố.\n",
    "    incident_state: Bang nơi sự cố xảy ra.\n",
    "    incident_city: Thành phố nơi sự cố xảy ra.\n",
    "    incident_location: Địa điểm cụ thể của sự cố.\n",
    "    incident_hour_of_the_day: Giờ trong ngày khi sự cố xảy ra.\n",
    "    number_of_vehicles_involved: Số lượng xe tham gia vào sự cố.\n",
    "    property_damage: Chỉ ra xem có thiệt hại tài sản nào không.\n",
    "    bodily_injuries: Số vết thương tật do sự cố.\n",
    "    witnesses: Số lượng nhân chứng cho sự cố.\n",
    "    police_report_available: Chỉ ra liệu có bản báo cáo của cảnh sát không.\n",
    "    total_claim_amount: Tổng số tiền đăng ký cho sự cố.\n",
    "    injury_claim: Số tiền đăng ký cho thương tích cá nhân.\n",
    "    property_claim: Số tiền đăng ký cho thiệt hại tài sản.\n",
    "    vehicle_claim: Số tiền đăng ký cho thiệt hại xe hơi.\n",
    "    auto_make: Hãng sản xuất của xe được bảo hiểm.\n",
    "    auto_model: Mô hình của xe được bảo hiểm.\n",
    "    auto_year: Năm sản xuất của xe được bảo hiểm.\n",
    "    fraud_reported: Chỉ ra liệu đơn đăng ký có được báo cáo là gian lận không.\n",
    "    _c39: Cột này dường như không đầy đủ hoặc là một giữ chỗ mà không có mô tả rõ ràng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5512f5",
   "metadata": {},
   "source": [
    "# 1. Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f8344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from numpy import set_printoptions\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdea320d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.27.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.18.0\n"
     ]
    }
   ],
   "source": [
    "init_notebook_mode(connected=True)\n",
    "print(__version__) # requires version >= 1.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0327b34b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/ADMIN/OneDrive/Documents/ads_final/ads_final/data/insurance_claims.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/ADMIN/OneDrive/Documents/ads_final/ads_final/data/insurance_claims.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\Data\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/ADMIN/OneDrive/Documents/ads_final/ads_final/data/insurance_claims.csv'"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('C:/Users/ADMIN/OneDrive/Documents/ads_final/ads_final/data/insurance_claims.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11250bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e85222",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(data, title=\"Pandas Profiling Report\")\n",
    "\n",
    "profile.to_file(\"EDA.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d339764",
   "metadata": {},
   "source": [
    "### Giải thích:\n",
    "    - Nhóm sử dụng thư viện Pandas-Profiling, là công cụ EDA nhanh chóng, cung cấp những kết luận sơ bộ về bộ dữ liệu để quá trình khám phá dữ liệu cho học máy trở nên dễ dàng hơn. Nhóm xuất ra file EDA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedadd26",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Phần lớn dữ liệu không có cột trống. Riêng có cột cuối cùng c_39 tất cả các cột đều bị bỏ trống. Dựa vào tên không có ý nghĩa lẫn khoảng trắng bỏ quá nhiều, Ta kết luận cột c_39 không có tác dụng gì hết nên chúng ta tiến hành bỏ nó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a87aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('_c39',axis=1,inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = list(data.select_dtypes(['object']).columns)\n",
    "len(object_columns)\n",
    "numeric_columns=list(data.select_dtypes('number'))\n",
    "len(numeric_columns)\n",
    "print(f\"Bien phan loai: {len(object_columns)}, Bien lien tuc: {len(numeric_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f32155",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b43a367",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[object_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c4473",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_columns: \n",
    "    print(\"\\033[1m\",\"*, Column: \", column,\"\\033[0m\")   \n",
    "    print('\\t',len(data[column].unique()), \"unique values\", \"\\t & \\t\", \n",
    "          data[column].notnull().sum(), \"non-null values\\t\", \n",
    "          round(100* data[column].notnull().sum()/len(data[column]),2), \n",
    "          \"% non-null\") \n",
    "    if len(data[column].unique())<=10:\n",
    "            print('\\t',data[column].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4a723",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Dựa vào thống kê các biến mang tính duy nhất ở các cột phân loại, chúng ta thấy có 2 cột mang tính chất phân loại có tác dụng như mã số, mỗi dòng là một số khác nhau không quá quan trọng trong bộ dữ liệu, chúng ta sẽ tiến hành bỏ nó\n",
    "- Ngoài ra chúng ta còn thấy có kiểu dữ liệu ngày tháng năm (datetime64ns), không tương thích với các mô hình dự đoán, chúng ta sẽ tiến hành rút trích sang các cột ngày tháng năm và loại bỏ hai cột policy_bind_date và incident_date\n",
    "- Cuối cùng, một số cột có xuất hiện ký tự đặc biệt là dấu '?'. Có thể là do khi thu thập, những hồ sơ này bị khuyết thiếu nên nhân sự bảo hiểm đã ghi chú lại bằng dấu ? thay cho việc để trống !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0554f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldata_categorical=(data[object_columns]=='?').sum()\n",
    "nulldata_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08486b7f",
   "metadata": {},
   "source": [
    "### Giải thích:\n",
    "Các cột như collision_type (loại hình va chạm), property_damage (thiệt hại tài sản), police_report_available (báo cáo của cảnh sát) không thế nào mang giá trị đặc biệt dấu '?' được. Có thể trong quá trình thu thập dữ liệu xuất hiện lỗi, sơ sót, hoặc điều tra viên, bộ phận thu thập dữ liệu không xác định rõ.\n",
    "Các thuộc tính trên có thể là một đặc trưng quan trọng trong những mô hình dự đoán liên quan đến mức độ thiệt hại hoặc hồ sơ thật giả của công ty bảo hiểm, cần lưu ý để tránh đưa ra sai sót trong quá trình phân tích dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed83fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_columns:\n",
    "    if len(data[column].unique())<=10:\n",
    "        print('-'*100)\n",
    "        print(\"*, Column: \", column)\n",
    "        print(data[column].value_counts())\n",
    "        print('-'*100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55763f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in object_columns:\n",
    "    if len(data[column].unique())<=40:\n",
    "        data[column].value_counts().iplot(kind='bar',title=column, \n",
    "                                        xTitle=column, \n",
    "                                        yTitle='Values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75895428",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95bd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[numeric_columns].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns: \n",
    "    print(\"*, Column: \", column)   \n",
    "    print(len(data[column].unique()), \"unique values\", \"\\t & \\t\", \n",
    "          data[column].notnull().sum(), \"non-null values\\t\", \n",
    "          round(100* data[column].notnull().sum()/len(data[column]),2), \n",
    "          \"% non-null\")\n",
    "    if len(data[column].unique())<=10:\n",
    "        print(data[column].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343cb455",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Dù là kiểu dữ liệu số, nhưng một số cột thuộc kiểu dữ liệu rời rạc chứ không phải kiểu dữ liệu liên tục ( ví dụ như là witnesses,...) mang vai trò như một phân lớp. Chúng ta sẽ chuyển kiểu dữ liệu các cột này sang kiểu dữ liệu mang tính phân loại để tăng hiệu suất dự án !\n",
    "- Các biến rời rạc nhưng chiếm khá nhiều giá trị như tuổi, để mô hình học máy học tốt hơn, nhóm cũng dự định chuyển sang thành cột phân loại với Young, Middle và Old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b8169",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_tocategory=[i for i in numeric_columns if len(data[i].unique())<=46]\n",
    "change_tocategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[change_tocategory]=data[change_tocategory].astype('object')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a14a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=list(data.select_dtypes('number'))\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numeric_columns:\n",
    "    data[c].iplot(kind='hist',title=c,xTitle=c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nulldata_numeric=(data[numeric_columns]==0).sum()\n",
    "nulldata_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in numeric_columns:\n",
    "    print(c)\n",
    "    data.hist(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e2d98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=data.select_dtypes(['number']).columns\n",
    "for c in numeric_columns:\n",
    "    plt.figure()\n",
    "    data.boxplot(c, rot=0, grid=True, fontsize=12);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5363200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(name,outliers_list):\n",
    "    we=data[name].values\n",
    "    Q1=np.quantile(we,0.25)\n",
    "    Q3=np.quantile(we,0.75)\n",
    "    IQR=Q3-Q1\n",
    "    print(\"Q1: \",Q1,\"Q3: \",Q3,\"IQR:\",IQR)\n",
    "    outliers=np.unique(we[[(n<Q1-1.5*IQR)|(n>Q3+1.5*IQR) for n in we]])\n",
    "    indexes=[we.tolist().index(i) for i in outliers]\n",
    "    if len(indexes)>0:\n",
    "        outliers_list.append(name)\n",
    "    print(\"Indexes of outliers: \", indexes)\n",
    "    print(\"Number of outliers: \", len(indexes))\n",
    "    print(\"Outlier values\", we[indexes])\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22927f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_list=[]\n",
    "for col in numeric_columns:\n",
    "    check_outliers(col,outliers_list)\n",
    "print(outliers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26ca926",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Các cột không chứa quá nhiều giá trị ngoại lệ. Ở bước tiền xử lý dữ liệu, chúng ta có thể xóa ngoại lệ để sử dụng MinMaxScaler để tiến hành chuẩn hóa dữ liệu số ( vì nhạy cảm với giá trị ngoại lệ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54874d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrle=data[numeric_columns].corr()\n",
    "corrle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f26dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corrle,vmin=-1,vmax=1, annot=False, fmt=\".2f\",cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af26052",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Các biến liên tục phần lớn không có sự tương quan nào hết.\n",
    "- Ta nhận thấy các giá trị như total_claim_amount, vehicle_claim, injury_claim, property_claim có sự tương quan thuận mạnh mẽ.Bởi vì total_claim_amount là tổng ba giá trị còn lại\n",
    "- incident_hour_of_the_day có mối quan hệ thuận với các bốn cột trên, chúng ta lưu ý để tiến hành phân tích xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d31c75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e194c5",
   "metadata": {},
   "source": [
    "## Chỉnh sửa dữ liệu\n",
    "- Sau những phân tích trên, chúng ta sẽ tiến hành chỉnh sửa data theo kết luận trước đó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72ad9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['incident_date']=pd.to_datetime(data['incident_date'])\n",
    "data['day']=data['incident_date'].dt.day\n",
    "data['month']=data['incident_date'].dt.month\n",
    "data['year']=data['incident_date'].dt.year\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['policy_bind_date','incident_date'],axis=1,inplace=True)\n",
    "object_columns = list(data.select_dtypes(['object']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884b15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['policy_number','insured_zip'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0196520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins=[19,30,50,64]\n",
    "labels=['Young','Middle','Old']\n",
    "data['age']=pd.cut(data.age,bins=bins,labels=labels,right=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a0eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,9,17,23]\n",
    "labels=['Morning','Evening','Night']\n",
    "data['incident_hour_of_the_day']=pd.cut(data.incident_hour_of_the_day,bins=bins,labels=labels,right=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df23fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=[0,2,120,497]\n",
    "labels=['None','N','Y']\n",
    "data['months_as_customer']=pd.cut(data.months_as_customer,bins=bins,labels=labels,right=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631aa1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fraud_reported.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='fraud_reported',data=data)\n",
    "plt.title(\"Biểu đồ thể hiện tương quan số hồ sơ bị báo cáo là gian lận\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8efebf",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Tỉ lệ số hồ sơ được cho là gian lận quá lớn, gấp 3 lần số bộ hồ sơ được chấp thuận. Đây có thể ảnh hưởng rất lớn tới mô hỉnh dự đoán khi biến mục tiêu xuất hiện tình trạng mất cân bằng (imbalanced variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af82faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x=\"policy_annual_premium\", y=\"fraud_reported\")\n",
    "plt.title('Biểu đồ boxplot thể hiện số tiền phí hàng năm theo độ thật giả yêu cầu đòi bồi thường')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcaaec3",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Có sự tương quan giữa policy_annual_prenium, các hồ sơ bị xác định gian lận có nhiều giá trị ngoại lệ về khoản tiền p đóng lệch xa khỏi hai khoảng râu của đồ thị. Hơn hết 50% các hồ sơ được xác định gian lận nằm ở (11000,14300) và 50% bộ hồ sơ được chấp thuận thì nằm trong khoảng (10400,14000)\n",
    "- Sự tương quan không được hiển thị rõ rệt vì độ chênh lệch giữa hai loại hồ sơ là quá lớn\n",
    "- Như vậy, ta có thể cân nhắc policy_annual_prenium là biến thích hợp đưa vào dự đoán\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80ffd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38002015",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.age.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4870f731",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='age',hue='fraud_reported', data=data)\n",
    "plt.title(\"Biểu đồ thể hiện lứa tuổi người yêu cầu bồi thường bảo hiểm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed9490",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insured_education_level.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e791431",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_Y=data[data.fraud_reported=='Y'].groupby('insured_education_level')['fraud_reported'].count().sort_values(ascending=False)\n",
    "occupation_Y.head(5).plot.bar()\n",
    "plt.title(\"Top 5 ngành nghề của khách hàng thuộc bộ hồ sơ được chấp thuận\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb63d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_N=data[data.fraud_reported=='N'].groupby('insured_education_level')['fraud_reported'].count().sort_values(ascending=False)\n",
    "occupation_N.head(5).plot.bar()\n",
    "plt.title(\"Top 5 ngành nghề của khách hàng thuộc bộ hồ sơ được cho là gian lận\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6ed1a",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Có thể thấy rõ có sự khác nhau về nghề nghiệp của khách hàng giữa bộ hồ sơ gian lận với được chấp thuận. \n",
    "- Chúng ta có thể cân nhắc đây có thể là một đặc trưng đưa vào mô hình dự đoán!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c5ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_request=data[data['fraud_reported']=='Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.insured_sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a047955",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='total_claim_amount', hue='insured_sex'); # histogram và phân loại\n",
    "plt.title(\"Biểu đồ thể hiện tương quan giới tính với tổng khoản chi bồ thường \")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc3916",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(data, x = 'total_claim_amount', col= 'insured_sex', kde = True) # chỉ vẽ kde: kind = 'kde'\n",
    "plt.suptitle('Phân phối tổng tiền bồi thường theo giới tính', y = 1.03)\n",
    "g.set_ylabels('Số hóa đơn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7eafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fraud_reported.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='fraud_reported',hue='insured_sex', data=data);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(data, x = 'total_claim_amount', col= 'fraud_reported', kde = True) # chỉ vẽ kde: kind = 'kde'\n",
    "plt.suptitle('Phân phối tổng tiền bồi thường theo hồ sơ hợp đồng', y = 1.03)\n",
    "g.set_ylabels('Số đơn yêu cầu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8234a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='total_claim_amount', hue='fraud_reported'); # histogram và phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.displot(data, x = 'total_claim_amount', col= 'insured_sex', row = 'fraud_reported', height=4,kde=True)\n",
    "plt.suptitle('Total_bill theo time và sex', y = 1.05)\n",
    "g.set_ylabels('Số hóa đơn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951fa0b",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Có thể thấy rõ biến giới tính không ảnh hưởng đến độ gian lận của bộ dữ liệu\n",
    "- Tổng số tiền bồi thường cũng không ảnh hưởng đến độ gian lận vì hình dáng của đường phân phối của hai biểu đồ trên tương đối giống nhau, có sự khác biệt lớn về ngoại quan là do tỉ lệ hai bộ hồ sơ được coi là gian lận và chấp thuận chênh lệch nhau quá nhiều"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=data, x=\"incident_hour_of_the_day\", y=\"total_claim_amount\")\n",
    "plt.title('Biểu đồ boxplot total_bill theo ngày')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990adf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='incident_hour_of_the_day',hue='fraud_reported',data=data)\n",
    "plt.title('Biểu đồ thể hiện khung giờ xảy ra tai nạn có ảnh hưởng đến đơn bồi thường không')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "# Vẽ biểu đồ ở hàng 0\n",
    "plt.subplot(1,2,1)\n",
    "data_Y=data[data['fraud_reported']=='Y']\n",
    "Y_contract=data_Y['incident_hour_of_the_day'].value_counts()\n",
    "Y_contract.plot(kind='pie')\n",
    "plt.ylabel('')  # Ẩn tiêu đề trục y cho subplot 1\n",
    "plt.title(\"Đối với hợp đồng được chấp thuận\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "data_N=data[data['fraud_reported']=='N']\n",
    "N_contract=data_N['incident_hour_of_the_day'].value_counts()\n",
    "N_contract.plot(kind='pie')\n",
    "plt.ylabel('')  # Ẩn tiêu đề trục y cho subplot 1\n",
    "plt.title(\"Đối với hợp đồng coi là gian lận\")\n",
    "\n",
    "\n",
    "\n",
    "# Tùy chỉnh tiêu đề\n",
    "plt.suptitle(\"Biểu đồ thể hiện sự ảnh hưởng của thời điểm xảy ra tai nạn với tỉ lệ được chấp thuận bồi thường\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# Hiển thị figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b3654",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Ở khung giờ sáng từ 3h đến 9h sáng có độ biến động dữ liệu cao khoảng tiền bồi thường có thể dao động từ con số nhỏ đến tận 60000 (đơn vị tiền tệ). Có thể do sáng sớm đoạn đường vắng mọi người có xu hướng chạy ẩu hoặc kẹt xe dễ xảy ra va chạm nên bộ dữ liệu biến động nhiều như vậy\n",
    "- Như vậy, incident_hour_of_day có sự tương quan đến việc hợp đồng có bị coi là gian lận hay ko, nhóm có thể cân nhắc thêm vào đặc trưng\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8294a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_claim=data[['injury_claim','property_claim','vehicle_claim']].sum()\n",
    "check_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8))\n",
    "plt.title('Phan phoi cac hoa don boi thuong ton that cac loai')\n",
    "plt.pie(check_claim, labels = check_claim.index, autopct = '%1.1f%%', startangle=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01dbc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='umbrella_limit', hue='fraud_reported'); # histogram và phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='months_as_customer', hue='fraud_reported'); # histogram và phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63967a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=data, x='policy_annual_premium', hue='fraud_reported'); # histogram và phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00636f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"muted\")\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "my_order = data.groupby(by=[\"auto_make\"])[\"total_claim_amount\"].median().iloc[::-1].index\n",
    "\n",
    "sns.boxplot(x = 'auto_make', y = 'total_claim_amount' ,data = data, order = my_order,palette=palette).set(title = 'Box Plot of Auto Model vs Total Claim Amount')\n",
    "plt.xticks(rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb0c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='auto_make',hue='fraud_reported', data=data)\n",
    "ax = plt.gca()\n",
    "\n",
    "# Xoay tiêu đề trục x\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9e2bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='auto_make', y='total_claim_amount', hue='fraud_reported', data=data)\n",
    "plt.title('Biểu đồ thể hiện tương quan giá tiền với hãng xe giữa hợp đồng được chấp thuận và bị coi là gian lận')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e82032",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Auto_make có thể là một đặc trưng của bộ dữ liệu. Ở biểu đồ boxplot, chúng ta có thể thấy, từng loại xe sẽ có sự phân bố và biến động khác nhau về khoản tiền đòi bồi thường, và hơn hết ở biểu đồ cột, chúng ta có thể thấy được số lượng xe đòi bồi thường ở mỗi hãng xe giữa hợp đồng được chấp thuận và bị coi gian lận ko đồng đều\n",
    "- Auto_make có thể là một biến tốt cho dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be2ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a79bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='policy_state',hue='fraud_reported', data=data)\n",
    "plt.title('Biểu đồ thể hiện tương quan trụ sở đăng ký bảo hiểm giữa hợp đồng được chấp thuận và bị coi là gian lận')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "# Vẽ biểu đồ ở hàng 0\n",
    "plt.subplot(2,2,1)\n",
    "data1=data[data['policy_csl']=='250/500']\n",
    "data1=data1['fraud_reported'].value_counts()\n",
    "data1.plot(kind='pie')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "data2=data[data['policy_csl']=='100/300']\n",
    "data2=data2['fraud_reported'].value_counts()\n",
    "data2.plot(kind='pie')\n",
    "\n",
    "plt.subplot(2,2,(3,4))\n",
    "data3=data[data['policy_csl']=='500/1000']\n",
    "data3=data3['fraud_reported'].value_counts()\n",
    "data3.plot(kind='pie')\n",
    "\n",
    "\n",
    "# Tùy chỉnh tiêu đề\n",
    "plt.suptitle(\"Biểu đồ thể hiện mức ưu đãi của bảo hiểm có ảnh hưởng đến yếu tố gian lận ko\")\n",
    "plt.tight_layout()\n",
    "# Hiển thị figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc574f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.pairplot(data=data, vars=[\"total_claim_amount\", \"day\"], hue='fraud_reported' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c1a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='vehicle_claim', y='total_claim_amount', data=data, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5834f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1298834",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['policy_csl'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7ba29",
   "metadata": {},
   "source": [
    "# 3. Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5973ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_dir = \"../exps\"\n",
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature1\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0754653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size=0.33\n",
    "seed=42\n",
    "data_train, data_test = train_test_split(data, test_size = 0.33, random_state=seed)\n",
    "print(data_train.shape,data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a81f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.to_excel(f'{exps_dir}/data/train.xlsx', index=None)\n",
    "data_test.to_excel(f'{exps_dir}/data/test.xlsx', index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850257cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns=list(data_train.select_dtypes('number'))\n",
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns = list(data_train.select_dtypes(['object']).columns)\n",
    "data_train[object_columns]=data_train[object_columns].astype('category')\n",
    "category_columns = list(data_train.select_dtypes(['category']).columns)\n",
    "np.savez(f'{exps_dir}/data/columns_dtype.npz', category_columns = category_columns, numeric_columns = numeric_columns)\n",
    "category_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cecbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, column):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "# Áp dụng hàm cho các cột chứa dữ liệu cần loại bỏ ngoại lệ\n",
    "for column in outliers_list:\n",
    "    data_train = remove_outliers_iqr(data_train, column)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7e73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(np.load(f'{exps_dir}/data/columns_dtype.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_train=='?').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['collision_type'].replace('?',np.nan,inplace=True)\n",
    "data_train['collision_type'].fillna(method='ffill',inplace=True)\n",
    "data_train[['property_damage','police_report_available']].replace('?','Unknow',inplace=True)\n",
    "(data_train=='?').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73058e",
   "metadata": {},
   "source": [
    "# 4.Chuẩn hóa dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4b827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols=list(data_train.select_dtypes('category'))\n",
    "numeric_cols=list(data_train.select_dtypes('number'))\n",
    "label_encoders = {}\n",
    "for column in category_cols:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data_train[column] = label_encoder.fit_transform(data_train[column])\n",
    "    label_encoders[column] = label_encoder  # Lưu trữ label encoder nếu cần sau này\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_train[numeric_cols] = scaler.fit_transform(data_train[numeric_cols])\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data_train.drop('fraud_reported',axis=1)\n",
    "y_train=data_train['fraud_reported']\n",
    "np.savez(f'{save_dir}/xy_training.npz', x_train = x_train, y_train = y_train)\n",
    "data_train.to_excel(f'{save_dir}/df_minmax.xlsx', index=False)\n",
    "x_train.to_excel(f'{save_dir}/x_train.xlsx', index=False)\n",
    "y_train.to_excel(f'{save_dir}/y_train.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cf2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce04b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"+ X_train: {len(x_train)}\")\n",
    "for fold, (train_idx, valid_idx) in enumerate(kfold.split(x_train, y_train)):\n",
    "    print(f'Fold {fold}: ')\n",
    "    print(f'+ train_idx: {train_idx}')\n",
    "    print(f'+ valid_idx: {valid_idx}')\n",
    "    print(f'+ train / valid: {valid_idx}')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72198f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_cols_test=dict(np.load(f'{exps_dir}/data/columns_dtype.npz'))['category_columns']\n",
    "numeric_cols_test=dict(np.load(f'{exps_dir}/data/columns_dtype.npz'))['numeric_columns']\n",
    "for column in outliers_list:\n",
    "    data_test = remove_outliers_iqr(data_test, column)\n",
    "data_test['collision_type'].replace('?',np.nan,inplace=True)\n",
    "data_test['collision_type'].fillna(method='ffill',inplace=True)\n",
    "data_test[['property_damage','police_report_available']].replace('?','Unknow',inplace=True)\n",
    "(data_test=='?').sum()\n",
    "label_encoders = {}\n",
    "for column in object_cols_test:\n",
    "    label_encoder = LabelEncoder()\n",
    "    data_test[column] = label_encoder.fit_transform(data_test[column])\n",
    "    label_encoders[column] = label_encoder  # Lưu trữ label encoder nếu cần sau này\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data_test[numeric_cols_test] = scaler.fit_transform(data_test[numeric_cols_test])\n",
    "\n",
    "x_test=data_test.drop('fraud_reported',axis=1)\n",
    "y_test=data_test['fraud_reported']\n",
    "data_test.to_excel(f'{save_dir}/df_test_minmax.xlsx', index=False)\n",
    "x_test.to_excel(f'{save_dir}/x_test.xlsx', index=False)\n",
    "y_test.to_excel(f'{save_dir}/y_test.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf7e092",
   "metadata": {},
   "source": [
    "# 5. Xây dựng và đánh giá mô hình học sâu Neutual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a929863",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unsupervised=pd.read_excel(f'{save_dir}/x_train.xlsx')\n",
    "Y_train_unsupervised=pd.read_excel(f'{save_dir}/y_train.xlsx')\n",
    "X_test_unsupervised=pd.read_excel(f'{save_dir}/x_test.xlsx')\n",
    "Y_test_unsupervised=pd.read_excel(f'{save_dir}/y_test.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee80ada6",
   "metadata": {},
   "source": [
    "Trên đây , là tập dữ liệu chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "\n",
    "X_train_unsupervised và Y_train_unsupervised thường là dữ liệu huấn luyện (input và output tương ứng), được sử dụng để huấn luyện mô hình.\n",
    "\n",
    "X_test_unsupervised và Y_test_unsupervised thường là dữ liệu kiểm tra (input và output tương ứng), được sử dụng để kiểm tra hiệu suất của mô hình đã huấn luyện trên dữ liệu mà nó chưa biết.\n",
    "\n",
    "Việc chia dữ liệu thành hai phần riêng biệt giúp đảm bảo mô hình không bị overfitting (quá khớp) vào dữ liệu huấn luyện và đánh giá khả năng tổng quát hóa của mô hình trên dữ liệu mới."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc05d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=240,activation='relu'))\n",
    "Dropout(0.5)\n",
    "model.add(Dense(units=120,activation='relu'))\n",
    "Dropout(0.5)\n",
    "model.add(Dense(units=60,activation='relu'))\n",
    "Dropout(0.5)\n",
    "model.add(Dense(units=30,activation='relu'))\n",
    "Dropout(0.5)\n",
    "model.add(Dense(units=15,activation='relu'))\n",
    "Dropout(0.5)\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "Dropout(0.5)\n",
    "\n",
    "# For a binary classification problem\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c958e",
   "metadata": {},
   "source": [
    "Khởi tạo Mô hình:\n",
    "\n",
    "Mô hình của chúng ta sử dụng một kiểu mô hình tuần tự, có nghĩa là các lớp được xếp chồng lên nhau một cách tuần tự, từ đầu vào đến đầu ra.\n",
    "Thêm Các Lớp:\n",
    "\n",
    "Chúng ta đã thêm một chuỗi các lớp \"Dense\" vào mô hình. Mỗi lớp \"Dense\" đại diện cho một nhóm neuron hoàn toàn kết nối với lớp trước đó.\n",
    "Sau mỗi lớp \"Dense\", chúng ta cũng thêm một lớp \"Dropout\". Lớp này giúp loại bỏ một số neuron ngẫu nhiên trong quá trình huấn luyện, giúp tránh việc mô hình quá khớp với dữ liệu huấn luyện.\n",
    "Lớp Cuối Cùng:\n",
    "\n",
    "Lớp đầu ra cuối cùng có một neuron và sử dụng hàm kích hoạt \"sigmoid\". Lớp này giúp dự đoán xác suất một điểm dữ liệu thuộc lớp positive trong bài toán phân loại.\n",
    "Compile Mô hình:\n",
    "\n",
    "Để chuẩn bị mô hình cho việc huấn luyện, chúng ta cần chỉ định các tham số bao gồm hàm mất mát (\"loss\") và thuật toán tối ưu hóa (\"optimizer\").\n",
    "Trong trường hợp này, chúng ta sử dụng \"binary_crossentropy\" cho bài toán phân loại nhị phân và \"adam\" là thuật toán tối ưu hóa.\n",
    "#Nói rõ hơn về Hàm mất mát \"loss\" : Đây là một chỉ số đo lường hiệu suất của mô hình dựa trên sự khác biệt giữa dự đoán và giá trị thực tế.\n",
    "Trong bài toán phân loại nhị phân (binary classification), chúng ta sử dụng hàm mất mát \"binary_crossentropy\". Đây là hàm mất mát thích hợp cho các bài toán phân loại nhị phân.\n",
    "#Nói rõ hơn về thuật toán tối ưu Optimier : Đây là thuật toán được sử dụng để tối ưu hóa mô hình bằng cách điều chỉnh các trọng số của mạng neural dựa trên hàm mất mát và dữ liệu huấn luyện.\n",
    "Trong trường hợp này, chúng ta sử dụng thuật toán tối ưu hóa \"adam\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c44960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 20)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=0.00001,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]\n",
    "checkpointer = ModelCheckpoint(filepath = \"Emotion_weights.hdf5\", verbose = 1, save_best_only=True)\n",
    "\n",
    "model.fit(x=X_train_unsupervised,y=Y_train_unsupervised,\n",
    "          validation_data=(X_test_unsupervised,Y_test_unsupervised),class_weight=class_weights_dict ,\n",
    "          batch_size=128,epochs=600,callbacks=[checkpointer, earlystopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4d8eb",
   "metadata": {},
   "source": [
    "Early Stopping: Đây là một kỹ thuật giúp dừng lại quá trình huấn luyện nếu không có cải thiện đáng kể trong hiệu suất của mô hình.\n",
    "Lệnh'restore_best_weights=True' để khôi phục trọng số tốt nhất khi quá trình huấn luyện kết thúc.\n",
    "\n",
    "Model Checkpoint\n",
    "Lưu trọng số của mô hình trong quá trình huấn luyện.\n",
    "Lệnh 'save_best_only=True' để chỉ lưu trọng số của mô hình khi có cải thiện trong hiệu suất.\n",
    "\n",
    "Fit Model\n",
    "Huấn luyện mô hình trên dữ liệu được chia thành tập huấn luyện và tập kiểm tra.\n",
    "'class_weight' là một tham số tùy chọn để cân bằng trọng số của các lớp, hữu ích trong việc xử lý các tập dữ liệu không cân bằng.\n",
    "\n",
    "'batch_size' là kích thước của từng batch dữ liệu được sử dụng trong quá trình huấn luyện.\n",
    "'epochs' chỉ ra số lượng epochs (vòng lặp) huấn luyện mô hình.\n",
    "\n",
    "'callbacks' chứa danh sách các callback để điều chỉnh mô hình trong quá trình huấn luyện. Trong trường hợp này, sử dụng các callbacks đã được định nghĩa trước."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ae5e3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb329d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026c12d9",
   "metadata": {},
   "source": [
    "Biểu đồ thể hiện loss và accuracy\n",
    "\n",
    "Hàm loss biểu thị mức độ lỗi của mô hình trong quá trình học tập\n",
    "\n",
    "Hàm accuracy biểu thị mức độ chính xác của mô hình trong việc dự đoán các dữ liệu trong tập kiểm tra.\n",
    "Theo biểu đồ, nhìn chung các đường thể hiện loss và accuracy biến động cho thấy mô hình có độ lỗi cao và độ chính xác thấp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict(X_test_unsupervised)\n",
    "predictions = np.argmax(probabilities, axis=-1)\n",
    "model.evaluate(X_test_unsupervised,Y_test_unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f218b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_unsupervised,Y_test_unsupervised)\n",
    "print(classification_report(Y_test_unsupervised,predictions))\n",
    "print(confusion_matrix(Y_test_unsupervised,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba74e0b",
   "metadata": {},
   "source": [
    "Dữ liệu đang gặp vấn đề về imbalance , ta thể thấy lớp 0 (không gian lận) có 239 mẫu, trong khi lớp 1 (gian lận) chỉ có 85 mẫu. Sự chênh lệch lớn về số lượng giữa các lớp thể hiện sự mất cân bằng trong dữ liệu.\n",
    "Precision, Recall, F1-score: Precision, recall và F1-score của lớp 1 (gian lận) đều bằng 0. Điều này có nghĩa là mô hình không tìm thấy dự đoán đúng cho lớp gian lận, không đạt được hiệu suất tốt trên lớp ít xuất hiện này.\n",
    "Dựa vào ma trận nhầm lẫn này , thông qua thông số của accuracy ta có thể thấy mô hình đã dự đoán đúng 74% trong tổng 324 mẫu test , tuy nhiên không thể dựa vào thông số này để đánh giá mô hình ( imblance )\n",
    "\n",
    "Trong bài toán của mình , bài toán kiểm tra hồ sơ có gian lận không ?\n",
    "Precision, recall và F1-score của lớp 1 (gian lận) đều là 0. Điều này có nghĩa là mô hình không tìm thấy dự đoán đúng cho lớp gian lận\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a418ea",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Nhóm xây dựng một mạng Netual network ứng dụng kỹ thuật trong học sâu như callbacks, đánh trọng số,.... Nhưng không khắc phục được tình trạng (imbalanced variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f25a95",
   "metadata": {},
   "source": [
    "# 6. Đánh giá và lựa chọn mô hình học máy có giám sát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec041628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelcheck_info(model,name):\n",
    "    print(name)\n",
    "    try:\n",
    "        coefficients = model.coef_.flatten()\n",
    "    except:\n",
    "        coefficients = model.feature_importances_.flatten()\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': x_train.columns,\n",
    "        'Coefficient': coefficients\n",
    "    })\n",
    "\n",
    "    print('bi loai bo',feature_importance[feature_importance['Coefficient'] == 0])\n",
    "    feature_importance = feature_importance[feature_importance['Coefficient'] != 0]\n",
    "    feature_importance['Absolute Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "    feature_importance.sort_values(by='Absolute Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "    print(\"Xếp hạng các đặc trưng theo mức độ quan trọng:\")\n",
    "    print(feature_importance[['Feature', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9927ca1f",
   "metadata": {},
   "source": [
    "Hiển thị thông tin liên quan đến đặc trưng quan trọng của mô hình và hệ số tương ứng nếu có"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53647cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_inRFE(model,name):\n",
    "    print(\"RFE\")\n",
    "    print(f\"Kiểm tra mô hình {name}\")\n",
    "    rfe=RFE(estimator=model, n_features_to_select=10)\n",
    "    fit=rfe.fit(x_train, y_train)\n",
    "#     print(\"Num Features: %d\"% fit.n_features_)\n",
    "#     print(\"Selected Features: %s\" % fit.support_)\n",
    "#     print(\"Features Ranking: %s\" %fit.ranking_)\n",
    "#     for index, value in enumerate(fit.ranking_):\n",
    "#         print(f\"{value}: {x_train.columns[index]}\")\n",
    "    sorted_columns = [x for _, x in sorted(zip(fit.ranking_, x_train.columns))]\n",
    "    sort=sorted(fit.ranking_)\n",
    "#     for i,j in zip(sort,sorted_columns):\n",
    "#         print(\"Columns sorted by RFE ranking\",i,\":\",j)\n",
    "    return [j for i,j in zip(sort,sorted_columns) if i==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3078b",
   "metadata": {},
   "source": [
    "Đoạn mã này thực hiện một phương pháp gọi là Recursive Feature Elimination (RFE), một kỹ thuật giảm số lượng đặc trưng trong mô hình dựa trên độ quan trọng của chúng. Mục đích của nó là lựa chọn ra tập các đặc trưng quan trọng nhất cho mô hình.\n",
    "\n",
    "Đoạn code này trả về tên của 10 đặc trưng được chọn, được sắp xếp theo mức độ quan trọng từ cao đến thấp. Điều này giúp tập trung vào các đặc trưng có ảnh hưởng lớn nhất đối với mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b7539",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(LogisticRegression())\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(DecisionTreeClassifier())\n",
    "names=['Logistic Regression','Linear Discriminant Analysis','Decision Tree Classifer']\n",
    "for model,name in zip(models,names):\n",
    "    check = model.fit(x_train, y_train)\n",
    "    selector = SelectFromModel(check, prefit=True)\n",
    "\n",
    "    selected_features = x_train.columns[(selector.get_support())]\n",
    "    modelcheck_info(model,name)\n",
    "    print(\"Các đặc trưng được chọn:\")\n",
    "    print(selected_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b85ef1",
   "metadata": {},
   "source": [
    "Thực hiện việc kiểm tra và in ra thông tin về mức độ quan trọng của các đặc trưng trong mô hình, đồng thời chỉ ra các đặc trưng được chọn bằng cách sử dụng các thuật toán khác nhau như Logistic Regression, Linear Discriminant Analysis và Decision Tree Classifier.\n",
    "\n",
    "Logistic Regression:\n",
    "Dựa vào kết quả mô hình chọn 7 đặc trưng quan trọng, bao gồm 'age', 'policy_state', 'policy_csl', 'umbrella_limit', 'insured_sex', 'incident_severity', 'property_damage'. \n",
    "Mức độ quan trọng của các đặc trưng được sắp xếp theo hệ số ảnh hưởng đến dự đoán của mô hình.\n",
    "Dựa vào đâu chọn : Chưa biết nhưng mà để ý cái nào hệ số dương và trên 0.1 thì được chọn\n",
    "\n",
    "Linear Discriminant Analysis:\n",
    "Mô hình chọn 11 đặc trưng quan trọng, bao gồm 'umbrella_limit', 'insured_sex', '#capital-gains', '#incident_severity', 'property_damage', 'total_claim_amount', '#injury_claim', 'property_claim', 'vehicle_claim', 'day', 'month'.\n",
    "Mức độ quan trọng được xác định dựa trên thuật toán LDA.\n",
    "\n",
    "Decision Tree Classifier:\n",
    "Mô hình chỉ chọn 9 đặc trưng quan trọng, bao gồm 'policy_annual_premium', 'insured_occupation', 'insured_hobbies', 'incident_severity', 'incident_location', 'police_report_available', 'property_claim', 'auto_year', 'day'.\n",
    "Mức độ quan trọng được xác định bằng thuật toán Decision Tree.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a716ab",
   "metadata": {},
   "source": [
    "Nhận xét : \n",
    "Các mô hình cho thấy sự khác nhau trong việc chọn đặc trưng quan trọng, có thể do cách mỗi mô hình xử lý và đánh giá mức độ quan trọng của đặc trưng khác nhau.\n",
    "'incident_severity', 'property_claim', 'umbrella_limit', 'insured_sex', 'age' là những đặc trưng xuất hiện nhiều trong các mô hình.\n",
    "Việc chọn đặc trưng quan trọng phụ thuộc vào thuật toán và cách mô hình xử lý dữ liệu, và có thể ảnh hưởng đến hiệu suất của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ba304",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "models.append(LogisticRegression())\n",
    "models.append(LinearDiscriminantAnalysis())\n",
    "models.append(DecisionTreeClassifier())\n",
    "models.append(RandomForestClassifier())\n",
    "\n",
    "\n",
    "names=['Logistic Regression','Linear Discriminant Analysis','Decision Tree Classifer','Random Forest']\n",
    "for model,name in zip(models,names):\n",
    "    model.fit(x_train,y_train)\n",
    "    print(feature_selection_inRFE(model,name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819aaef5",
   "metadata": {},
   "source": [
    "Tạo ra một danh sách các mô hình máy học (Logistic Regression, Linear Discriminant Analysis, Decision Tree Classifier, Random Forest) và lưu chúng vào biến models. Sau đó, nó chạy vòng lặp qua mỗi mô hình để thực hiện việc lựa chọn đặc trưng sử dụng phương pháp Recursive Feature Elimination (RFE)\n",
    "\n",
    "Nhận xét :\n",
    "Các mô hình máy học chọn các đặc trưng khác nhau làm quan trọng cho việc dự đoán.\n",
    "Mỗi mô hình có danh sách đặc trưng quan trọng riêng, có thể là do cách mà mỗi thuật toán hiểu và tận dụng thông tin trong dữ liệu khác nhau.\n",
    "Điều này thể hiện sự đa dạng và sự khác biệt trong cách mà các thuật toán học máy xử lý dữ liệu và ước lượng đặc trưng quan trọng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb2cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_models=[KNeighborsClassifier(),GaussianNB(),MLPClassifier(),GradientBoostingClassifier(),MultinomialNB(),SVC(class_weight=class_weights_dict)]\n",
    "names=['K Neighbors Classifier','Gau','Netual Network','Boosting','Naive','SVC']\n",
    "def feature_selection_inKBest(model, name):\n",
    "    print(f'Lua chon dac trung {name}')\n",
    "    k_best = SelectKBest(score_func=f_classif, k=11)\n",
    "    fit = k_best.fit(x_train, y_train)\n",
    "    selected_features = fit.get_support()\n",
    "    selected_column_names = x_train.columns[selected_features]\n",
    "    return selected_column_names\n",
    "\n",
    "for model,name in zip(special_models,names):\n",
    "    print(feature_selection_inKBest(model, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216acd04",
   "metadata": {},
   "source": [
    "Dùng để chọn đặc trưng sử dụng phương pháp SelectKBest từ thư viện Scikit-learn. Phương pháp này đánh giá đặc trưng dựa trên các điểm số (score) và lựa chọn ra K đặc trưng tốt nhất (K là số được xác định trước, trong trường hợp này là 11).Mục đích chính của đoạn mã này là thực hiện việc lựa chọn các đặc trưng quan trọng từ mỗi mô hình để sử dụng trong việc xây dựng mô hình học máy.\n",
    "\n",
    "\n",
    "Nhìn kết quả ta có thể thấy rằng :\n",
    "Mặc dù chạy nhiều mô hình khác nhau nhưng đều cho ra cùng một tập hợp đặc trưng bao gồm 'age', 'policy_state', 'umbrella_limit', 'insured_sex', 'incident_severity', 'incident_city', 'property_damage', 'total_claim_amount', 'property_claim', 'vehicle_claim', 'day'.\n",
    "\n",
    "Có thể kết luận rằng từ các mô hình khác nhau, việc lựa chọn đặc trưng đều ổn định và không thay đổi, cho thấy rằng tập hợp đặc trưng này có vẻ quan trọng và ảnh hưởng đáng kể đến dự đoán của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143c4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(name,model,X,Y,names,results,scoring):\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cv_results=cross_val_score(model,X,Y,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg=scoring.title()+\" %s: %.3f%% (%.3f%%)\"%(name,cv_results.mean()*100,cv_results.std()*100)\n",
    "    print(msg)       \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f838ccaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X=x_train\n",
    "X_logistic=x_train[['insured_hobbies', 'incident_severity', 'incident_city', 'auto_make',\n",
    "       'auto_model']]\n",
    "X_linear=x_train[['policy_csl', 'umbrella_limit', 'insured_sex', 'incident_severity',\n",
    "       'property_damage', 'bodily_injuries', 'witnesses',\n",
    "       'police_report_available', 'injury_claim', 'vehicle_claim', 'day']]\n",
    "X_decision=x_train[['policy_annual_premium', 'insured_hobbies', 'incident_severity',\n",
    "       'incident_location', 'property_claim', 'auto_make']]\n",
    "X_forest=x_train[['auto_model', 'day', 'incident_location', 'incident_severity',\n",
    "'injury_claim', 'insured_hobbies', 'policy_annual_premium', 'property_claim', 'total_claim_amount', 'vehicle_claim']]\n",
    "Y=y_train\n",
    "num_folds=5\n",
    "seed=7\n",
    "models=[]\n",
    "\n",
    "models.append(('KNN',KNeighborsClassifier(n_neighbors=100)))\n",
    "models.append(('NB',GaussianNB()))\n",
    "models.append(('SVM',SVC(class_weight=class_weights_dict)))\n",
    "models.append(('NN',MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)))\n",
    "models.append(('GD',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)))\n",
    "models.append(('Naive',MultinomialNB()))\n",
    "\n",
    "\n",
    "RandomForestClassifier(n_estimators=500, \n",
    "                                max_depth=10, \n",
    "                                min_samples_split=400, \n",
    "                                random_state=12, \n",
    "                                class_weight=class_weights_dict,\n",
    "                                )\n",
    "\n",
    "results=[]\n",
    "names=[]\n",
    "scorings=['accuracy','precision','recall','f1']\n",
    "#check_model('LR',LogisticRegression(class_weight=class_weights_dict),X_logistic,Y,names,results,scorings)\n",
    "#check_model('LDA',LinearDiscriminantAnalysis(),X_linear,Y,names,results,scorings)\n",
    "#check_model('CART',DecisionTreeClassifier(class_weight=class_weights_dict),X_decision,Y,names,results,scorings)\n",
    "#check_model('RD',RandomForestClassifier(n_estimators=100, random_state=42,class_weight=class_weights_dict),X_forest,Y,names,results,scorings)\n",
    "\n",
    "\n",
    "\n",
    "for scoring in scorings:\n",
    "    check_model('LR',LogisticRegression(class_weight=class_weights_dict),X_logistic,Y,names,results,scoring)\n",
    "    check_model('LDA',LinearDiscriminantAnalysis(),X_linear,Y,names,results,scoring)\n",
    "    check_model('CART',DecisionTreeClassifier(class_weight=class_weights_dict),X_decision,Y,names,results,scoring)\n",
    "    check_model('RD',RandomForestClassifier(n_estimators=100, random_state=42,class_weight=class_weights_dict),X_forest,Y,names,results,scoring)\n",
    "    for name,model in models:\n",
    "        kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "        cv_results=cross_val_score(model,x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']],Y,cv=kfold,scoring=scoring)\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg=scoring.title()+\" %s: %.3f%% (%.3f%%)\"%(name,cv_results.mean()*100,cv_results.std()*100)\n",
    "        print(msg)\n",
    "    fig=plt.figure()\n",
    "    fig.suptitle(f'So sánh tương quan {scoring.title()} các loại mô hình')\n",
    "    ax=fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()\n",
    "    results=[]\n",
    "    names=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a0bee5",
   "metadata": {},
   "source": [
    "Đoạn code trên thực hiện các thao tác :\n",
    "\n",
    "- Chia dữ liệu: Tách dữ liệu thành các tập con tương ứng với từng mô hình.\n",
    "\n",
    "- Xây dựng các mô hình: Sử dụng một loạt các mô hình khác nhau như KNN, Naive Bayes, SVM, Neural Network, Gradient Boosting, và Random Forest.\n",
    "\n",
    "- Đánh giá các mô hình: Sử dụng cross-validation để đánh giá hiệu suất của từng mô hình theo các điểm số khác nhau như accuracy, precision, recall và F1-score.\n",
    "\n",
    "- Trực quan hóa kết quả: Hiển thị các biểu đồ boxplot so sánh hiệu suất của các mô hình theo từng điểm số.\n",
    "\n",
    "Nhận xét kết quả : \n",
    "Mô hình LDA là lựa chọn tốt nhất tổng thể, khi xét cả độ chính xác, precision, recall và F1-score. Mô hình này có độ chính xác cao nhất, với giá trị trung bình là 81.25%, độ lệch chuẩn thấp, cho thấy tính ổn định tốt. Mô hình LDA cũng có precision và F1-score cao, cho thấy khả năng nhận diện các trường hợp dương tính và cân bằng giữa precision và recall tốt.\n",
    "\n",
    "Mô hình NN là lựa chọn thay thế tiềm năng nếu cần độ chính xác cao. Mô hình này có độ chính xác cao thứ hai, với giá trị trung bình là 81.094%, độ lệch chuẩn cao hơn LDA một chút. Tuy nhiên, precision và F1-score của NN thấp hơn LDA một chút.\n",
    "Mô hình CART cũng là lựa chọn thay thế tiềm năng nếu cần độ chính xác cao. Mô hình này có độ chính xác cao thứ ba, với giá trị trung bình là 80.486%, độ lệch chuẩn cao hơn LDA và NN một chút. Precision và F1-score của CART tương đương với NN.\n",
    "\n",
    "Các mô hình còn lại cần cân nhắc cẩn thận tùy theo nhu cầu cụ thể của ứng dụng. Các mô hình này có độ chính xác thấp hơn LDA, NN và CART. Các mô hình này có thể phù hợp cho các ứng dụng có yêu cầu độ chính xác thấp hơn hoặc các yêu cầu cụ thể khác về precision, recall hoặc F1-score.\n",
    "\n",
    "\n",
    "Kết luận :\n",
    "Các mô hình phân loại cho bài toán dự đoán rủi ro bảo hiểm có độ chính xác tương đối cao. Mô hình LDA là lựa chọn tốt nhất tổng thể, với độ chính xác cao, ổn định và cân bằng giữa precision và recall. Các mô hình NN và CART cũng là những lựa chọn tiềm năng tùy theo nhu cầu cụ thể của ứng dụng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a23326",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_result={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80347ef",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b62a338",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['insured_hobbies', 'incident_severity', 'incident_city', 'auto_make',\n",
    "       'auto_model']]\n",
    "supervied_target=y_train\n",
    "model=LogisticRegression(class_weight=class_weights_dict)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6563d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['insured_hobbies', 'incident_severity', 'incident_city', 'auto_make',\n",
    "       'auto_model']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['LogisticRegression']=classification_report(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf3fd4",
   "metadata": {},
   "source": [
    "### Gaussian NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdb5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=GaussianNB()\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['GaussianNB']=classification_report(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea5c286",
   "metadata": {},
   "source": [
    "### MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884982c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=MultinomialNB()\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['MultinomialNB']=classification_report(y_test, predictions)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f60371f",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d068540",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=MLPClassifier(hidden_layer_sizes=(100,), max_iter=500)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d164f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['MLPClassifier']=classification_report(y_test, predictions)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cc4e1",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a01eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=42)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e290c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['GradientBoostingClassifier']=classification_report(y_test, predictions)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0cf408",
   "metadata": {},
   "source": [
    "### Kết luận:\n",
    "- Nhìn vào đồ thị có thể thấy giá trị trung vị của mô hình Random Forest là cao nhất theo scoring=\"Accuracy\"\n",
    "- Mô hình LDA là mô hình ít bị biến động nhất và mô hình GD là một mô hình cân đối khi vừa có tỉ lệ ít biến động vừa có khoảng trung vị cao tương đối"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba633c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13d3f27f",
   "metadata": {},
   "source": [
    "### Mô hình SVM\n",
    "      -Tỉ lệ đoán sai ở lớp bị đánh trọng số thấp cao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d55f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=SVC(class_weight=class_weights_dict)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e224f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['age', 'policy_state', 'umbrella_limit', 'insured_sex',\n",
    "       'incident_severity', 'incident_city', 'property_damage',\n",
    "       'total_claim_amount', 'property_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['SVM']=classification_report(y_test, predictions)\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d29cb86",
   "metadata": {},
   "source": [
    "### Mô hình LDA\n",
    "    -Có kết quả đứng thứ hai, tập test được đánh giá có kết quả khả quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['policy_csl', 'umbrella_limit', 'insured_sex', 'incident_severity',\n",
    "       'property_damage', 'bodily_injuries', 'witnesses',\n",
    "       'police_report_available', 'injury_claim', 'vehicle_claim', 'day']]\n",
    "supervied_target=y_train\n",
    "model=LinearDiscriminantAnalysis()\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fbac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['policy_csl', 'umbrella_limit', 'insured_sex', 'incident_severity',\n",
    "       'property_damage', 'bodily_injuries', 'witnesses',\n",
    "       'police_report_available', 'injury_claim', 'vehicle_claim', 'day']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Hiển thị ma trận nhầm lẫn\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['LDA']=classification_report(y_test, predictions)\n",
    "\n",
    "# Hiển thị báo cáo phân loại để xem thêm thông tin chi tiết\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99a5eb9",
   "metadata": {},
   "source": [
    "## 2 Mô hình đạt điểm cao nhất là:\n",
    "    -RD: RandomForest\n",
    "    -CART: DecisionTreeClassifer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fca4f6",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8d893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['policy_annual_premium', 'insured_hobbies', 'incident_severity',\n",
    "       'incident_location', 'property_claim', 'auto_make']]\n",
    "supervied_target=y_train\n",
    "model=DecisionTreeClassifier(class_weight=class_weights_dict)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c39654",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['policy_annual_premium', 'insured_hobbies', 'incident_severity',\n",
    "       'incident_location', 'property_claim', 'auto_make']])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['DecisionTreeClassifer']=classification_report(y_test, predictions)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121d659",
   "metadata": {},
   "source": [
    "### Mô hình Random Forest\n",
    "    - Có dấu hiệu tích cực hơn SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervied_features=x_train[['auto_model', 'day', 'incident_location', 'incident_severity',\n",
    "'injury_claim', 'insured_hobbies', 'policy_annual_premium', 'property_claim', 'total_claim_amount', 'vehicle_claim']]\n",
    "supervied_target=y_train\n",
    "model=RandomForestClassifier(n_estimators=100, random_state=42,class_weight=class_weights_dict)\n",
    "model.fit(supervied_features,supervied_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[['auto_model', 'day', 'incident_location', 'incident_severity',\n",
    "'injury_claim', 'insured_hobbies', 'policy_annual_premium', 'property_claim', 'total_claim_amount', 'vehicle_claim']])\n",
    "\n",
    "# Tạo ma trận nhầm lẫn\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Hiển thị ma trận nhầm lẫn\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Class\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.show()\n",
    "evaluate_result['RD']=classification_report(y_test, predictions)\n",
    "\n",
    "# Hiển thị báo cáo phân loại để xem thêm thông tin chi tiết\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea619ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in evaluate_result.items():\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b837f1",
   "metadata": {},
   "source": [
    "### Nhận xét tổng quát và lựa chọn mô hình \n",
    "\n",
    "Logistic Regression: Precision và Recall của lớp 1 đều tương đối cao, tuy nhiên, có thể cần cải thiện F1-score.\n",
    "\n",
    "GaussianNB và MultinomialNB: Cả hai mô hình có độ chính xác thấp đối với lớp 1.\n",
    "\n",
    "MLPClassifier: Độ chính xác cho lớp 1 cũng không cao.\n",
    "\n",
    "GradientBoostingClassifier: Có F1-score khá tốt cho cả hai lớp, nhưng recall cho lớp 1 thấp hơn.\n",
    "\n",
    "SVM: Có độ chính xác cao cho lớp 0, nhưng độ chính xác cho lớp 1 thấp.\n",
    "\n",
    "LDA: Cũng có F1-score và độ chính xác khá tốt cho lớp 0, nhưng thấp hơn cho lớp 1.\n",
    "\n",
    "DecisionTreeClassifier và Random Forest: Cả hai mô hình đều có độ chính xác và F1-score tốt cho cả hai lớp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb846d",
   "metadata": {},
   "source": [
    "###  Chọn mô hình \n",
    "Dựa trên các chỉ số, DecisionTreeClassifier và Random Forest phù hợp hơn với bài toán phân loại gian lận. Cả hai mô hình này có độ chính xác tốt cho cả hai lớp và F1-score cao.\n",
    "### Lựa chọn mô hình \n",
    "Random Forest có thể là lựa chọn tốt hơn vì nó có khả năng giảm overfitting, ổn định hơn và thường mang lại kết quả tốt trong nhiều trường hợp. Mô hình này có độ chính xác cao và hiệu suất tốt cho cả hai lớp, điều này quan trọng trong việc dự đoán các trường hợp gian lận và không gian lận. Đồng thời, DecisionTreeClassifier cũng là một sự lựa chọn khả quan nếu bạn muốn mô hình đơn giản và dễ hiểu hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe10617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(prediction):\n",
    "    if prediction==1:\n",
    "        return \"Y\"\n",
    "    else:\n",
    "        return \"N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4361df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b81715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_output(stt,model, X_test, Y_test):\n",
    "    print(f\"Lần thứ {stt}: \")\n",
    "    indx = rd.randint(0, X_test.shape[0] - 1)  # Đảm bảo indx nằm trong giới hạn của DataFrame\n",
    "    sample = X_test.iloc[indx, :].values        # Chuyển DataFrame thành mảng NumPy\n",
    "    sample = np.expand_dims(sample, axis=0)     # Mở rộng kích thước cho phù hợp với mô hình\n",
    "    y_predict = model.predict(sample)\n",
    "    Y_check = check_result(Y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict):\n",
    "        return True\n",
    "    else: return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3eefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_check=10\n",
    "solandung=0\n",
    "for i in range(n_check):\n",
    "    if check_output(i+1,model, x_test[['auto_model', 'day', 'incident_location', 'incident_severity',\n",
    "'injury_claim', 'insured_hobbies', 'policy_annual_premium', 'property_claim', 'total_claim_amount', 'vehicle_claim']], y_test):\n",
    "        solandung+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a65590",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng: {solandung} chiếm khoảng {(solandung/n_check)*100}% tổng lần dự đoán\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075b835",
   "metadata": {},
   "outputs": [],
   "source": [
    "solandung=0\n",
    "for indx in range(len(x_test)):\n",
    "    sample = x_test[['auto_model', 'day', 'incident_location', 'incident_severity',\n",
    "'injury_claim', 'insured_hobbies', 'policy_annual_premium', 'property_claim', 'total_claim_amount', 'vehicle_claim']].iloc[indx, :].values        # Chuyển DataFrame thành mảng NumPy\n",
    "    sample = np.expand_dims(sample, axis=0)     # Mở rộng kích thước cho phù hợp với mô hình\n",
    "    y_predict = model.predict(sample)\n",
    "    Y_check = check_result(y_test.iloc[indx])\n",
    "    print('True:', Y_check)\n",
    "    print('Predicted:', check_result(y_predict))\n",
    "    print(\"----------------------------\")\n",
    "    if Y_check==check_result(y_predict):\n",
    "        solandung+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4e62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Số lần dự đoán đúng trong lan kiểm tra: {solandung} chiếm khoảng {(solandung/len(x_test))*100}% tổng lần dự đoán\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d5430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d230486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2fe14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
